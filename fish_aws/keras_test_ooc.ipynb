{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "np.random.seed(2016)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import log_loss\n",
    "from keras import __version__ as keras_version\n",
    "import data_set_ooc\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = dict()\n",
    "FLAGS['width'] = 32\n",
    "FLAGS['height'] = 32\n",
    "FLAGS['batch_size'] = 20\n",
    "FLAGS['kernel_1_out'] = 8\n",
    "FLAGS['kernel_2_out'] = 8\n",
    "FLAGS['conv2_input_width'] = 16\n",
    "FLAGS['conv2_input_height'] = 16\n",
    "FLAGS['n_classes'] = 8\n",
    "FLAGS['learning_rate'] = 0.001\n",
    "FLAGS['batch_size'] = 16\n",
    "FLAGS['n_epochs'] = 5\n",
    "FLAGS['train_report_step'] = 20\n",
    "FLAGS['val_report_step'] = 80\n",
    "FLAGS['keep_prob'] = 0.75\n",
    "FLAGS['reg'] = 0.01\n",
    "FLAGS['epochs'] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data_set_ooc.DataSet(width = FLAGS['width'], height=FLAGS['height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading next batch\n",
      "Read train data time: 1.93 seconds\n"
     ]
    }
   ],
   "source": [
    "bx, by = data.next_batch(FLAGS['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val, y_val = data.get_validation_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "tb = TensorBoard(log_dir='keras_tb/', histogram_freq=5, write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(32, 32, 3)))\n",
    "    model.add(Convolution2D(4, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(4, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(8, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(8, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "    sgd = SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3021 samples, validate on 756 samples\n",
      "INFO:tensorflow:Summary name convolution2d_1_W:0 is illegal; using convolution2d_1_W_0 instead.\n",
      "INFO:tensorflow:Summary name convolution2d_1_b:0 is illegal; using convolution2d_1_b_0 instead.\n",
      "INFO:tensorflow:Summary name convolution2d_2_W:0 is illegal; using convolution2d_2_W_0 instead.\n",
      "INFO:tensorflow:Summary name convolution2d_2_b:0 is illegal; using convolution2d_2_b_0 instead.\n",
      "INFO:tensorflow:Summary name convolution2d_3_W:0 is illegal; using convolution2d_3_W_0 instead.\n",
      "INFO:tensorflow:Summary name convolution2d_3_b:0 is illegal; using convolution2d_3_b_0 instead.\n",
      "INFO:tensorflow:Summary name convolution2d_4_W:0 is illegal; using convolution2d_4_W_0 instead.\n",
      "INFO:tensorflow:Summary name convolution2d_4_b:0 is illegal; using convolution2d_4_b_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1_W:0 is illegal; using dense_1_W_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1_b:0 is illegal; using dense_1_b_0 instead.\n",
      "INFO:tensorflow:Summary name dense_2_W:0 is illegal; using dense_2_W_0 instead.\n",
      "INFO:tensorflow:Summary name dense_2_b:0 is illegal; using dense_2_b_0 instead.\n",
      "INFO:tensorflow:Summary name dense_3_W:0 is illegal; using dense_3_W_0 instead.\n",
      "INFO:tensorflow:Summary name dense_3_b:0 is illegal; using dense_3_b_0 instead.\n",
      "Epoch 1/30\n",
      "16s - loss: 1.6622 - val_loss: 1.5902\n",
      "Epoch 2/30\n",
      "10s - loss: 1.5961 - val_loss: 1.5859\n",
      "Epoch 3/30\n",
      "9s - loss: 1.5898 - val_loss: 1.5848\n",
      "Epoch 4/30\n",
      "9s - loss: 1.5885 - val_loss: 1.5836\n",
      "Epoch 5/30\n",
      "10s - loss: 1.5825 - val_loss: 1.5845\n",
      "Epoch 6/30\n",
      "11s - loss: 1.5846 - val_loss: 1.5829\n",
      "Epoch 7/30\n",
      "12s - loss: 1.5827 - val_loss: 1.5840\n",
      "Epoch 8/30\n",
      "9s - loss: 1.5830 - val_loss: 1.5838\n",
      "Epoch 9/30\n",
      "8s - loss: 1.5825 - val_loss: 1.5826\n",
      "Epoch 10/30\n",
      "10s - loss: 1.5817 - val_loss: 1.5832\n",
      "Epoch 11/30\n",
      "15s - loss: 1.5823 - val_loss: 1.5833\n",
      "Epoch 12/30\n",
      "12s - loss: 1.5814 - val_loss: 1.5833\n",
      "Epoch 13/30\n",
      "10s - loss: 1.5820 - val_loss: 1.5837\n",
      "Epoch 14/30\n",
      "11s - loss: 1.5820 - val_loss: 1.5831\n",
      "Epoch 15/30\n",
      "9s - loss: 1.5802 - val_loss: 1.5823\n",
      "Epoch 16/30\n",
      "12s - loss: 1.5815 - val_loss: 1.5824\n",
      "Epoch 17/30\n",
      "10s - loss: 1.5812 - val_loss: 1.5823\n",
      "Epoch 18/30\n",
      "10s - loss: 1.5813 - val_loss: 1.5823\n",
      "Epoch 19/30\n",
      "9s - loss: 1.5812 - val_loss: 1.5825\n",
      "Epoch 20/30\n",
      "10s - loss: 1.5814 - val_loss: 1.5825\n",
      "Epoch 21/30\n",
      "13s - loss: 1.5808 - val_loss: 1.5830\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=5, verbose=0),\n",
    "tb]\n",
    "hist = model.fit(data.X_train, data.y_train, batch_size=FLAGS['batch_size'], nb_epoch=FLAGS['epochs'],\n",
    "          shuffle=True, verbose=2, validation_data=(X_val, y_val),\n",
    "              callbacks=callbacks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 0 of 1000\n",
      "loading 20 of 1000\n",
      "loading 40 of 1000\n",
      "loading 60 of 1000\n",
      "loading 80 of 1000\n",
      "loading 100 of 1000\n",
      "loading 120 of 1000\n",
      "loading 140 of 1000\n",
      "loading 160 of 1000\n",
      "loading 180 of 1000\n",
      "loading 200 of 1000\n",
      "loading 220 of 1000\n",
      "loading 240 of 1000\n",
      "loading 260 of 1000\n",
      "loading 280 of 1000\n",
      "loading 300 of 1000\n",
      "loading 320 of 1000\n",
      "loading 340 of 1000\n",
      "loading 360 of 1000\n",
      "loading 380 of 1000\n",
      "loading 400 of 1000\n",
      "loading 420 of 1000\n",
      "loading 440 of 1000\n",
      "loading 460 of 1000\n",
      "loading 480 of 1000\n",
      "loading 500 of 1000\n",
      "loading 520 of 1000\n",
      "loading 540 of 1000\n",
      "loading 560 of 1000\n",
      "loading 580 of 1000\n",
      "loading 600 of 1000\n",
      "loading 620 of 1000\n",
      "loading 640 of 1000\n",
      "loading 660 of 1000\n",
      "loading 680 of 1000\n",
      "loading 700 of 1000\n",
      "loading 720 of 1000\n",
      "loading 740 of 1000\n",
      "loading 760 of 1000\n",
      "loading 780 of 1000\n",
      "loading 800 of 1000\n",
      "loading 820 of 1000\n",
      "loading 840 of 1000\n",
      "loading 860 of 1000\n",
      "loading 880 of 1000\n",
      "loading 900 of 1000\n",
      "loading 920 of 1000\n",
      "loading 940 of 1000\n",
      "loading 960 of 1000\n",
      "loading 980 of 1000\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = load_images.load_test(width = FLAGS['width'], \n",
    "                                                      height=FLAGS['height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, batch_size=FLAGS['batch_size'], verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import make_submission\n",
    "submit = make_submission.makeSubmission(preds,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit.to_csv('keras_32_32.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
